{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding for Self-Driving Cars\n",
    "\n",
    "When humans drive on the road, we rely heavily on lane line-markings to steer our vehicles. The objective of this project is to teach the lane detection ability to a computer as shown in the video below. This project continues upon the work done in the [Basic Lane Finding Project](https://github.com/ssharma1991/autonomous-car-basic-lane-detection) and aims to improve the accuracy and robustness of previous approach.\n",
    "\n",
    "<img src=\"test_images_output/test2.jpg\" width=\"720\" title=\"Image Processing Pipeline\"/>\n",
    "\n",
    "Images and video files from a dashcam mounted in a car is used as input. Jupyter notebook, Python and OpenCV are used to detect and visualize the lane lines in the input. The anaconda environment being used is available as the [CarND Term1 Starter Kit](https://github.com/udacity/CarND-Term1-Starter-Kit/blob/master/README.md) (if you run any errors, update the packages).\n",
    "\n",
    "## Image Processing Pipeline\n",
    "\n",
    "To find the lane lines on a road, a pipeline consisting of computer vision techniques in is implemented in `pipeline()` function. The operations are performed in the following sequence:\n",
    "1. **Input:** An Input image is received by the pipeline. It is be scaled down to 360x640 pixels to standardize size and improve algorithm speed.\n",
    "2. **Camera Correction:** Camera distortion is an intrinsic property of any image taken by a lens based camera. This distortion is compensated for by a calibration process carried out by `CalibrateCamera()` function which calculates the *Camera Matrix* and the *Distortion Coefficients*. A set of chessboard images is used as input. Then, using the distortion parameters, the undistorted image can be calculated.\n",
    "3. **Sobel Thresholding:** The Sobel operator with `Kernel size=3` is used to extract gradient information from the dashcam image. A combination of both direction and magnitude based thresholding is done for better lane detection and is implemented in `sobel_thresh()` function.\n",
    "4. **HLS Augmentation:** Useful lane information can also be extracted using color based thresholding. For this technique, we convert RGB images to HLS images and thresholding the H-channel and S-channel. Use of Adaptive Histogram Equalization helps in gathering relevant lane data. This result is combined with Sobel thresholding in `aug_HLS_thresh()` function to generate the final binary image. This step increases robustness in cases with shadows and variation in road texture. \n",
    "5. **Bird's Eye View:** Lane information is easier to process in a birds-eye view of the road. An appropriate prespective transformation is used to convert the binary image into top-down view of the road. Pixel data of reference points in a straight lane are used to create a trapezoid and transform it into a rectangle. `prespective()` function implements this process.\n",
    "6. **Lane Pixel Detection:** In this step, left and right lane pixels are detected and grouped together. A histogram and tolerance window is used to approximately isolate lane pixels from surrounding noise in the `find_lane_pixels()` function.\n",
    "7. **Lane Curve Calculation:** Next, a second order quadratic curve is fitted to approximate the lane lines. Lane data is stored as instances of the `line` class. `fit_polynomial_new()` function is used to implement this process.\n",
    "8. **Inverse Projection:** To visualize the lanes, the detected curves need to be projected back on the image. `invProj()` function accomplishes this.\n",
    "9. **Lane Parameters Calculation:** Once the lane pixels are calculated, they can be mapped to real environment using standard lane guidlines set by the US Department of Transportation. The curve is used to calculate the curvature of lane and location of car within the lane. `measure_curvature_pixels()` and  `measure_location_in_lane()` functions are used to implement this process. \n",
    "10. **Final Visualization:** Finally, the lane data is superimposed with camera view to visualize and debug the workings of the algorithm. Numerical estimation of lane curvature and vehicle position are displayed as text on top of the image. `visualize()` function implements this process.\n",
    "\n",
    "The image below displays each step in the pipeline.\n",
    "\n",
    "<img src=\"test_images_output/test2_detail.jpg\" width=\"900\" title=\"Image Processing Pipeline\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Step 4- Lane Pixel Detection and Curve Fitting\n",
    " In a video, lane data from previous frames is be used to improve the efficiency of the process. Finally, \n",
    "\n",
    "## Results\n",
    "A video captured by a camera installed in a car is processed and the algorithm for lane detection is run. The results have been shown in the video available [here][video1]\n",
    "\n",
    "\n",
    "## Discussion\n",
    "The lane detection by the current algorithm can be less accurate when shadows on road exist. Also, improvements need to be made to handle more challenging videos.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
